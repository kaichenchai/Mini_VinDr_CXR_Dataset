2025-06-24 21:52:32,043 INFO    MainThread:1180293 [wandb_setup.py:_flush():76] Current SDK version is 0.16.5
2025-06-24 21:52:32,043 INFO    MainThread:1180293 [wandb_setup.py:_flush():76] Configure stats pid to 1180293
2025-06-24 21:52:32,043 INFO    MainThread:1180293 [wandb_setup.py:_flush():76] Loading settings from /home/kai/.config/wandb/settings
2025-06-24 21:52:32,043 INFO    MainThread:1180293 [wandb_setup.py:_flush():76] Loading settings from /mnt/data/kai/VinDr_Code/Mini_VinDr_CXR_Dataset/pytorch_model_training/wandb/settings
2025-06-24 21:52:32,043 INFO    MainThread:1180293 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-06-24 21:52:32,043 INFO    MainThread:1180293 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-06-24 21:52:32,043 INFO    MainThread:1180293 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'pytorch_model_training/test.py', 'program_abspath': '/mnt/data/kai/VinDr_Code/Mini_VinDr_CXR_Dataset/pytorch_model_training/test.py', 'program': '/mnt/data/kai/VinDr_Code/Mini_VinDr_CXR_Dataset/pytorch_model_training/test.py'}
2025-06-24 21:52:32,044 INFO    MainThread:1180293 [wandb_setup.py:_flush():76] Applying login settings: {}
2025-06-24 21:52:32,044 INFO    MainThread:1180293 [wandb_init.py:_log_setup():527] Logging user logs to /mnt/data/kai/VinDr_Code/Mini_VinDr_CXR_Dataset/pytorch_model_training/wandb/run-20250624_215232-2p1ub3w0/logs/debug.log
2025-06-24 21:52:32,044 INFO    MainThread:1180293 [wandb_init.py:_log_setup():528] Logging internal logs to /mnt/data/kai/VinDr_Code/Mini_VinDr_CXR_Dataset/pytorch_model_training/wandb/run-20250624_215232-2p1ub3w0/logs/debug-internal.log
2025-06-24 21:52:32,044 INFO    MainThread:1180293 [wandb_init.py:init():567] calling init triggers
2025-06-24 21:52:32,044 INFO    MainThread:1180293 [wandb_init.py:init():574] wandb.init called with sweep_config: {}
config: {'model': 'fasterrcnn_resnet50_fpn_v2', 'epochs': 5, 'batch_size': 16, 'optimizer': 'AdamW', 'learning_rate': 0.0001}
2025-06-24 21:52:32,044 INFO    MainThread:1180293 [wandb_init.py:init():617] starting backend
2025-06-24 21:52:32,044 INFO    MainThread:1180293 [wandb_init.py:init():621] setting up manager
2025-06-24 21:52:32,045 INFO    MainThread:1180293 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-06-24 21:52:32,050 INFO    MainThread:1180293 [wandb_init.py:init():629] backend started and connected
2025-06-24 21:52:32,051 INFO    MainThread:1180293 [wandb_init.py:init():721] updated telemetry
2025-06-24 21:52:32,054 INFO    MainThread:1180293 [wandb_init.py:init():754] communicating run to backend with 90.0 second timeout
2025-06-24 21:52:32,788 INFO    MainThread:1180293 [wandb_run.py:_on_init():2344] communicating current version
2025-06-24 21:52:33,134 INFO    MainThread:1180293 [wandb_run.py:_on_init():2353] got version response upgrade_message: "wandb version 0.20.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2025-06-24 21:52:33,135 INFO    MainThread:1180293 [wandb_init.py:init():805] starting run threads in backend
2025-06-24 21:52:34,261 INFO    MainThread:1180293 [wandb_run.py:_console_start():2323] atexit reg
2025-06-24 21:52:34,261 INFO    MainThread:1180293 [wandb_run.py:_redirect():2178] redirect: wrap_raw
2025-06-24 21:52:34,261 INFO    MainThread:1180293 [wandb_run.py:_redirect():2243] Wrapping output streams.
2025-06-24 21:52:34,261 INFO    MainThread:1180293 [wandb_run.py:_redirect():2268] Redirects installed.
2025-06-24 21:52:34,261 INFO    MainThread:1180293 [wandb_init.py:init():848] run started, returning control to user process
2025-06-24 21:54:24,146 WARNING MsgRouterThr:1180293 [router.py:message_loop():77] message_loop has been closed
